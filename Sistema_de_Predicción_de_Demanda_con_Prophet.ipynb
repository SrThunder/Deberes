{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SrThunder/Deberes/blob/master/Sistema_de_Predicci%C3%B3n_de_Demanda_con_Prophet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from prophet import Prophet\n",
        "import streamlit as st\n",
        "import io\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import openai\n",
        "\n",
        "# Cargar variables de entorno desde .env\n",
        "load_dotenv()\n",
        "# Configurar la clave de la API de OpenAI\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# --- Funciones Principales ---\n",
        "\n",
        "# 1. Generar Pronósticos de Demanda por Campaña (pronostico_demanda.py)\n",
        "def generar_pronostico_demanda(datos_historicos, detalles_campana, n_pasos=30):\n",
        "    \"\"\"\n",
        "    Genera pronósticos de demanda para una campaña específica, incluyendo intervalos de confianza,\n",
        "    utilizando el modelo Prophet para series de tiempo multivariadas.\n",
        "\n",
        "    Args:\n",
        "        datos_historicos (pd.DataFrame): DataFrame con datos históricos de ventas, incluyendo columnas como 'fecha', 'ventas', 'campana' y otras variables relevantes.\n",
        "        detalles_campana (dict): Diccionario con detalles de la campaña actual, incluyendo 'nombre' y 'fecha_inicio'.\n",
        "        n_pasos (int, opcional): Número de pasos a predecir en el futuro. Por defecto, 30.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Un tuple que contiene:\n",
        "            - pd.DataFrame: DataFrame con las predicciones de demanda, incluyendo las columnas 'fecha', 'prediccion' y los intervalos de confianza de Prophet.\n",
        "            - str: Una conclusión accionable basada en el pronóstico.\n",
        "    \"\"\"\n",
        "    # Filtrar datos para la campaña específica\n",
        "    datos_campana = datos_historicos[datos_historicos['campana'] == detalles_campana['nombre']].copy()\n",
        "\n",
        "    # Asegurarse de que la columna 'fecha' sea de tipo datetime y renombrarla a 'ds'\n",
        "    datos_campana['ds'] = pd.to_datetime(datos_campana['fecha'])\n",
        "\n",
        "    # Verificar si hay datos para la campaña\n",
        "    if datos_campana.empty:\n",
        "        return pd.DataFrame(columns=['ds', 'yhat', 'yhat_lower', 'yhat_upper']), \"No hay datos disponibles para la campaña especificada.\"\n",
        "\n",
        "    # Seleccionar las columnas relevantes para Prophet\n",
        "    columnas_prophet = ['ds', 'ventas'] + [col for col in datos_campana.columns if col not in ['fecha', 'ventas', 'campana']]\n",
        "    datos_prophet = datos_campana[columnas_prophet].rename(columns={'ventas': 'y'})\n",
        "\n",
        "    # Crear y entrenar el modelo Prophet\n",
        "    modelo = Prophet()\n",
        "    for col in datos_prophet.columns:\n",
        "        if col not in ['ds', 'y']:\n",
        "            modelo.add_regressor(col)  # Agregar regresores externos\n",
        "    modelo.fit(datos_prophet)\n",
        "\n",
        "    # Crear un DataFrame para las predicciones futuras\n",
        "    futuro = modelo.make_future_dataframe(periods=n_pasos)\n",
        "    for col in datos_prophet.columns:\n",
        "        if col not in ['ds', 'y']:\n",
        "            futuro[col] = datos_prophet[col].iloc[-n_pasos:].values  # Extender regresores al futuro\n",
        "\n",
        "    # Generar predicciones\n",
        "    pronostico = modelo.predict(futuro)\n",
        "\n",
        "    # Generar conclusión accionable\n",
        "    aumento_porcentaje = (pronostico['yhat'].iloc[-1] / datos_prophet['y'].mean() - 1) * 100\n",
        "    if aumento_porcentaje > 10:\n",
        "        conclusion = f\"Se espera un aumento significativo en la demanda. Aumente el inventario en un {aumento_porcentaje:.0f}% para productos clave en la campaña actual.\"\n",
        "    elif aumento_porcentaje < -10:\n",
        "        conclusion = f\"Se espera una disminución en la demanda. Considere reducir el inventario en un {abs(aumento_porcentaje):.0f}% para optimizar costos.\"\n",
        "    else:\n",
        "        conclusion = \"Se espera una demanda similar a los niveles históricos. Mantenga el inventario actual.\"\n",
        "\n",
        "    # Renombrar la columna ds a fecha para mantener la consistencia\n",
        "    pronostico = pronostico.rename(columns={'ds': 'fecha'})\n",
        "\n",
        "    return pronostico, conclusion\n",
        "\n",
        "\n",
        "\n",
        "# 2. Análisis Geográfico de Alto Potencial (analisis_geografico.py)\n",
        "def analizar_geografia_demanda(datos_historicos):\n",
        "    \"\"\"\n",
        "    Analiza datos geográficos y de ventas para identificar regiones de alta demanda.\n",
        "    Esta función no cambia significativamente con el cambio a Prophet, pero se mantiene\n",
        "    para la consistencia de la estructura del sistema.\n",
        "\n",
        "    Args:\n",
        "        datos_historicos (pd.DataFrame): DataFrame con datos históricos de ventas, incluyendo columnas como 'region', 'ventas'.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Un tuple que contiene:\n",
        "            - pd.DataFrame: DataFrame con el análisis de demanda por región, incluyendo las columnas 'region' y 'demanda_proyectada'.\n",
        "            - str: Una recomendación accionable basada en el análisis geográfico.\n",
        "    \"\"\"\n",
        "    # Verificar si la columna 'region' existe\n",
        "    if 'region' not in datos_historicos.columns:\n",
        "        raise ValueError(\"La columna 'region' no existe en el DataFrame.\")\n",
        "\n",
        "    # Calcular la demanda total por región\n",
        "    demanda_por_region = datos_historicos.groupby('region')['ventas'].sum().reset_index()\n",
        "\n",
        "    # Proyectar la demanda (ejemplo simple: crecimiento promedio)\n",
        "    crecimiento_promedio = datos_historicos['ventas'].pct_change().mean()\n",
        "    demanda_por_region['demanda_proyectada'] = demanda_por_region['ventas'] * (1 + crecimiento_promedio)\n",
        "\n",
        "    # Identificar la región de mayor crecimiento\n",
        "    region_max_crecimiento = demanda_por_region.loc[demanda_por_region['demanda_proyectada'].idxmax()]\n",
        "    crecimiento_porcentaje = (region_max_crecimiento['demanda_proyectada'] / demanda_por_region['ventas'].mean() - 1) * 100\n",
        "    recomendacion = f\"Dirija campañas hacia la región {region_max_crecimiento['region']}, donde se espera un crecimiento del {crecimiento_porcentaje:.0f}%.\"\n",
        "\n",
        "    return demanda_por_region, recomendacion\n",
        "\n",
        "\n",
        "\n",
        "# 3. Identificación de Productos Estacionales (estacionalidad.py)\n",
        "def identificar_productos_estacionales(datos_historicos):\n",
        "    \"\"\"\n",
        "    Identifica productos con demanda estacional y sus ciclos.\n",
        "    Esta función no cambia con el cambio a Prophet, pero se mantiene para la consistencia.\n",
        "\n",
        "    Args:\n",
        "        datos_historicos (pd.DataFrame): DataFrame con datos históricos de ventas, incluyendo columnas como 'fecha', 'producto', 'ventas'.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Un tuple que contiene:\n",
        "            - dict: Un diccionario donde las claves son los productos y los valores son DataFrames con el análisis estacional ('mes' y 'ventas_promedio').\n",
        "            - dict: Un diccionario de recomendaciones accionables por producto.\n",
        "    \"\"\"\n",
        "    # Asegurarse de que la columna 'fecha' sea de tipo datetime\n",
        "    datos_historicos['fecha'] = pd.to_datetime(datos_historicos['fecha'])\n",
        "\n",
        "    # Verificar si las columnas 'producto' y 'ventas' existen\n",
        "    if 'producto' not in datos_historicos.columns or 'ventas' not in datos_historicos.columns:\n",
        "        raise ValueError(\"El DataFrame debe contener las columnas 'producto' y 'ventas'.\")\n",
        "\n",
        "    # Agrupar datos por producto y mes\n",
        "    datos_historicos['mes'] = datos_historicos['fecha'].dt.month\n",
        "    ventas_mensuales = datos_historicos.groupby(['producto', 'mes'])['ventas'].mean().reset_index()\n",
        "\n",
        "    # Calcular ventas promedio por mes para cada producto\n",
        "    productos_estacionales = {}\n",
        "    recomendaciones = {}\n",
        "    for producto in ventas_mensuales['producto'].unique():\n",
        "        datos_producto = ventas_mensuales[ventas_mensuales['producto'] == producto].copy()\n",
        "        datos_producto['mes_nombre'] = datos_producto['mes'].apply(lambda x: calendar.month_abbr[x]) # Convertir número de mes a nombre\n",
        "        productos_estacionales[producto] = datos_producto\n",
        "        # Identificar el mes de mayor venta\n",
        "        mes_max_venta = datos_producto.loc[datos_producto['ventas'].idxmax()]\n",
        "        recomendaciones[producto] = f\"Se espera que el producto {producto} tenga su mayor demanda en {mes_max_venta['mes_nombre']}.\"\n",
        "\n",
        "    return productos_estacionales, recomendaciones\n",
        "\n",
        "\n",
        "\n",
        "# 4. Impacto de Promociones (impacto_promociones.py)\n",
        "def analizar_impacto_promociones(datos_historicos, datos_promociones):\n",
        "    \"\"\"\n",
        "    Analiza el impacto de las promociones en la demanda.\n",
        "    Esta función no cambia significativamente con el cambio a Prophet.\n",
        "\n",
        "    Args:\n",
        "        datos_historicos (pd.DataFrame): DataFrame con datos históricos de ventas, incluyendo columnas como 'fecha', 'ventas', y opcionalmente 'promocion_id'.\n",
        "        datos_promociones (pd.DataFrame): DataFrame con datos de promociones, incluyendo columnas como 'promocion_id', 'fecha_inicio', 'fecha_fin', 'tipo'.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Un tuple que contiene:\n",
        "            - pd.DataFrame: DataFrame con el análisis del impacto de las promociones.\n",
        "            - dict: Un diccionario con conclusiones accionables por promoción.\n",
        "    \"\"\"\n",
        "    # Asegurarse de que las columnas 'fecha' sean de tipo datetime\n",
        "    datos_historicos['fecha'] = pd.to_datetime(datos_historicos['fecha'])\n",
        "    if not datos_promociones.empty:\n",
        "        datos_promociones['fecha_inicio'] = pd.to_datetime(datos_promociones['fecha_inicio'])\n",
        "        datos_promociones['fecha_fin'] = pd.to_datetime(datos_promociones['fecha_fin'])\n",
        "\n",
        "    # Si no hay promociones, retornar dataframes vacíos\n",
        "    if datos_promociones.empty:\n",
        "        return pd.DataFrame(), {}\n",
        "\n",
        "    # Fusionar datos de ventas y promociones (asumiendo que hay una columna 'promocion_id' en datos_historicos)\n",
        "    datos_combinados = pd.merge(datos_historicos, datos_promociones, on='promocion_id', how='left')\n",
        "\n",
        "    # Calcular el impacto de cada promoción\n",
        "    impacto_promociones = datos_combinados.groupby('promocion_id')['ventas'].mean().reset_index()\n",
        "    impacto_promociones = impacto_promociones.rename(columns={'ventas': 'ventas_promedio'})\n",
        "\n",
        "    # Calcular ventas promedio sin promoción (para comparar)\n",
        "    ventas_sin_promocion = datos_historicos[datos_historicos['promocion_id'].isnull()]['ventas'].mean()\n",
        "    impacto_promociones['ventas_sin_promocion'] = ventas_sin_promocion\n",
        "\n",
        "    # Calcular el incremento porcentual en ventas\n",
        "    impacto_promociones['incremento_porcentaje'] = ((impacto_promociones['ventas_promedio'] / ventas_sin_promocion) - 1) * 100\n",
        "\n",
        "    # Generar conclusiones accionables\n",
        "    conclusiones = {}\n",
        "    for _, row in impacto_promociones.iterrows():\n",
        "        promocion_id = row['promocion_id']\n",
        "        incremento = row['incremento_porcentaje']\n",
        "        if incremento > 0:\n",
        "            conclusiones[promocion_id] = f\"Se estima un incremento del {incremento:.0f}% en las ventas debido a la promoción {promocion_id}.\"\n",
        "        else:\n",
        "            conclusiones[promocion_id] = f\"La promoción {promocion_id} no tuvo un impacto positivo en las ventas.\"\n",
        "\n",
        "    return impacto_promociones, conclusiones\n",
        "\n",
        "\n",
        "\n",
        "# 5. Carga y Validación de Datos (carga_datos.py)\n",
        "def cargar_y_validar_datos(archivo):\n",
        "    \"\"\"\n",
        "    Carga y valida datos desde un archivo CSV o Excel.\n",
        "\n",
        "    Args:\n",
        "        archivo (str o BytesIO): Ruta al archivo de datos o BytesIO object.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame con los datos cargados, o None si hay un error.\n",
        "        str: Mensaje indicando el resultado de la carga y validación.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if isinstance(archivo, str):  # Si es una ruta de archivo\n",
        "            if archivo.endswith('.csv'):\n",
        "                datos = pd.read_csv(archivo)\n",
        "            elif archivo.endswith(('.xls', '.xlsx')):\n",
        "                datos = pd.read_excel(archivo)\n",
        "            else:\n",
        "                return None, \"Formato de archivo no soportado. Por favor, use CSV o Excel.\"\n",
        "        elif isinstance(archivo, io.BytesIO): #Si es un objeto BytesIO\n",
        "             # Determinar el formato basado en el nombre del archivo (si está disponible)\n",
        "            # Esto es una simplificación, st.file_uploader no siempre proporciona el nombre real\n",
        "            if hasattr(archivo, 'name'):\n",
        "                if archivo.name.endswith('.csv'):\n",
        "                    datos = pd.read_csv(archivo)\n",
        "                elif archivo.name.endswith(('.xls', '.xlsx')):\n",
        "                    datos = pd.read_excel(archivo)\n",
        "                else:\n",
        "                    return None, \"Formato de archivo no soportado. Por favor, use CSV o Excel.\"\n",
        "            else:\n",
        "                return None, \"No se pudo determinar el formato del archivo.  Por favor, use CSV o Excel.\"\n",
        "\n",
        "        else:\n",
        "            return None, \"Tipo de archivo no soportado. Por favor, use CSV o Excel.\"\n",
        "\n",
        "        # Validación básica de columnas (puedes agregar validaciones más específicas)\n",
        "        if not all(col in datos.columns for col in ['fecha', 'ventas']):\n",
        "            return None, \"El archivo debe contener las columnas 'fecha' y 'ventas'.\"\n",
        "\n",
        "        # Convertir la columna 'fecha' a datetime, si existe\n",
        "        if 'fecha' in datos.columns:\n",
        "            try:\n",
        "                datos['fecha'] = pd.to_datetime(datos['fecha'])\n",
        "            except ValueError:\n",
        "                return None, \"La columna 'fecha' no tiene un formato de fecha válido.\"\n",
        "\n",
        "        return datos, \"Datos cargados y validados exitosamente.\"\n",
        "    except Exception as e:\n",
        "        return None, f\"Error al cargar el archivo: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "# 6. Generación de Insights con OpenAI (insights.py)\n",
        "def generar_insights_openai(resultados, funcion_nombre):\n",
        "    \"\"\"\n",
        "    Genera insights y recomendaciones usando la API de OpenAI.\n",
        "\n",
        "    Args:\n",
        "        resultados (pd.DataFrame o dict): Resultados de una de las funciones de análisis.\n",
        "        funcion_nombre (str): Nombre de la función que generó los resultados ('generar_pronostico_demanda', 'analizar_geografia_demanda', 'identificar_productos_estacionales', 'analizar_impacto_promociones').\n",
        "\n",
        "    Returns:\n",
        "        str: Un texto con los insights y recomendaciones generados por la API de OpenAI.\n",
        "    \"\"\"\n",
        "    if resultados is None or (isinstance(resultados, pd.DataFrame) and resultados.empty) or (isinstance(resultados, dict) and not resultados):\n",
        "        return \"No hay resultados para analizar.\"\n",
        "\n",
        "    prompt = f\"Analiza los siguientes resultados de la función {funcion_nombre} y proporciona insights y recomendaciones accionables para un Director de Ventas o Marketing:\\n\\n\"\n",
        "\n",
        "    if funcion_nombre == 'generar_pronostico_demanda':\n",
        "        prompt += f\"Datos: {resultados.to_string()}\\n\\n\"\n",
        "        prompt += \"Interpreta las predicciones de demanda de la serie de tiempo, los intervalos de confianza, y sugiere acciones para optimizar el inventario y la planificación de la campaña.  Considera que se está utilizando el modelo Prophet.\"\n",
        "    elif funcion_nombre == 'analizar_geografia_demanda':\n",
        "        prompt += f\"Datos: {resultados.to_string()}\\n\\n\"\n",
        "        prompt += \"Identifica las regiones con mayor potencial de crecimiento y sugiere estrategias para enfocar los esfuerzos de marketing y ventas.\"\n",
        "    elif funcion_nombre == 'identificar_productos_estacionales':\n",
        "        prompt += f\"Datos: {resultados}\\n\\n\" # Los resultados de estacionalidad ya están en formato dict\n",
        "        prompt += \"Describe los patrones de estacionalidad de los productos y recomienda acciones para optimizar la promoción y el inventario a lo largo del año.\"\n",
        "    elif funcion_nombre == 'analizar_impacto_promociones':\n",
        "        prompt += f\"Datos: {resultados.to_string()}\\n\\n\"\n",
        "        prompt += \"Evalúa la efectividad de las promociones y sugiere mejoras para futuras campañas.\"\n",
        "    else:\n",
        "        return \"Función no soportada.\"\n",
        "\n",
        "    try:\n",
        "        response = openai.Completion.create(\n",
        "            engine=\"gpt-3.5-turbo-instruct\",  # Puedes ajustar el motor según tus necesidades\n",
        "            prompt=prompt,\n",
        "            max_tokens=200,  # Limita la longitud de la respuesta\n",
        "            temperature=0.7,  # Ajusta la creatividad de la respuesta\n",
        "        )\n",
        "        return response.choices[0].text.strip()\n",
        "    except Exception as e:\n",
        "        return f\"Error al contactar a la API de OpenAI: {e}\"\n",
        "\n",
        "\n",
        "\n",
        "# --- Interfaz de Usuario con Streamlit (main.py) ---\n",
        "def main():\n",
        "    st.title(\"Sistema de Predicción de Demanda\")\n",
        "\n",
        "    # Cargar datos\n",
        "    archivo = st.file_uploader(\"Cargar Datos Históricos (CSV, Excel)\", type=[\"csv\", \"xls\", \"xlsx\"])\n",
        "    if archivo is not None:\n",
        "        # Para st.file_uploader, el archivo se carga como un objeto BytesIO\n",
        "        datos_historicos, mensaje = cargar_y_validar_datos(archivo)\n",
        "        if datos_historicos is not None:\n",
        "            st.success(mensaje)\n",
        "\n",
        "            # Agregamos un st.cache_data() para que Streamlit no re-ejecute el análisis cada vez.\n",
        "            @st.cache_data()\n",
        "            def calcular_resultados(datos_historicos):\n",
        "                # Asegurarse de que los datos no son None\n",
        "                if datos_historicos is None or datos_historicos.empty:\n",
        "                    return None, None, None, None\n",
        "\n",
        "                detalles_campana_ejemplo = {'nombre': datos_historicos['campana'].unique()[0], 'fecha_inicio': datos_historicos['fecha'].min()} # Ejemplo\n",
        "                resultados_pronostico, _ = generar_pronostico_demanda(datos_historicos, detalles_campana_ejemplo, n_pasos=30) #n_pasos\n",
        "                analisis_region, _ = analizar_geografia_demanda(datos_historicos)\n",
        "                productos_estacionales, _ = identificar_productos_estacionales(datos_historicos)\n",
        "                # Ejemplo de datos de promociones (puedes cargar esto también si es necesario)\n",
        "                datos_promociones_ejemplo = pd.DataFrame({\n",
        "                    'promocion_id': [1, 2],\n",
        "                    'fecha_inicio': pd.to_datetime(['2023-01-01', '2023-03-01']),\n",
        "                    'fecha_fin': pd.to_datetime(['2023-01-31', '2023-03-31']),\n",
        "                    'tipo': ['Descuento', '2x1']\n",
        "                })\n",
        "                impacto_promociones, _ = analizar_impacto_promociones(datos_historicos, datos_promociones_ejemplo)\n",
        "                return resultados_pronostico, analisis_region, productos_estacionales, impacto_promociones\n",
        "\n",
        "            resultados_pronostico, analisis_region, productos_estacionales, impacto_promociones = calcular_resultados(datos_historicos)\n",
        "\n",
        "            # --- Pestañas ---\n",
        "            tab1, tab2, tab3, tab4 = st.tabs([\"Pronósticos\", \"Análisis Geográfico\", \"Productos Estacionales\", \"Impacto Promociones\"])\n",
        "\n",
        "            with tab1:\n",
        "                st.header(\"Pronósticos de Demanda por Campaña\")\n",
        "                if resultados_pronostico is not None and not resultados_pronostico.empty:\n",
        "                    # Crear el gráfico con Streamlit\n",
        "                    st.subheader(f'Pronóstico de Demanda para la Campaña: {datos_historicos[\"campana\"].unique()[0]}')\n",
        "                    # Asegurarse de que 'fecha' esté en el DataFrame\n",
        "                    if 'fecha' in resultados_pronostico:\n",
        "                        chart_data = resultados_pronostico[['fecha', 'yhat', 'yhat_lower', 'yhat_upper']].set_index('fecha')\n",
        "                        st.line_chart(chart_data)\n",
        "                    else:\n",
        "                        st.warning(\"La columna 'fecha' no está presente en los resultados del pronóstico.\")\n",
        "\n",
        "                    # Mostrar la conclusión de OpenAI\n",
        "                    insight_pronostico = generar_insights_openai(resultados_pronostico, 'generar_pronostico_demanda')\n",
        "                    st.write(insight_pronostico)\n",
        "                else:\n",
        "                    st.warning(\"No hay datos disponibles para generar el pronóstico.\")\n",
        "\n",
        "            with tab2:\n",
        "                st.header(\"Análisis Geográfico de Alto Potencial\")\n",
        "                if analisis_region is not None and not analisis_region.empty:\n",
        "                    # Crear el gráfico de barras con Streamlit\n",
        "                    st.subheader('Demanda Proyectada por Región')\n",
        "                    st.bar_chart(analisis_region.set_index('region'))\n",
        "                    insight_geografia = generar_insights_openai(analisis_region, 'analizar_geografia_demanda')\n",
        "                    st.write(insight_geografia)\n",
        "                else:\n",
        "                    st.warning(\"No hay datos disponibles para el análisis geográfico.\")\n",
        "\n",
        "            with tab3:\n",
        "                st.header(\"Identificación de Productos Estacionales\")\n",
        "                if productos_estacionales:\n",
        "                    for producto, datos_producto in productos_estacionales.items():\n",
        "                        st.subheader(f'Ventas Mensuales Promedio para {producto}')\n",
        "                        st.bar_chart(datos_producto.set_index('mes_nombre'))\n",
        "                    insight_estacionalidad = generar_insights_openai(productos_estacionales, 'identificar_productos_estacionales')\n",
        "                    st.write(insight_estacionalidad)\n",
        "                else:\n",
        "                    st.warning(\"No hay datos disponibles para el análisis de estacionalidad.\")\n",
        "\n",
        "            with tab4:\n",
        "                st.header(\"Impacto de Promociones\")\n",
        "                if impacto_promociones is not None and not impacto_promociones.empty:\n",
        "                    # Crear el gráfico de barras con Streamlit\n",
        "                    st.subheader('Impacto de las Promociones en Ventas')\n",
        "                    chart_data_promociones = impacto_promociones[['promocion_id', 'ventas_promedio', 'ventas_sin_promocion']].set_index('promocion_id')\n",
        "                    st.bar_chart(chart_data_promociones)\n",
        "                    insight_promociones = generar_insights_openai(impacto_promociones, 'analizar_impacto_promociones')\n",
        "                    st.write(insight_promociones)\n",
        "                else:\n",
        "                    st.warning(\"No hay datos disponibles para el análisis de promociones.\")\n",
        "        else:\n",
        "            st.error(mensaje)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "N6KkoiLrUMyu"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}